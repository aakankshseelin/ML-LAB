{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:58.424342Z",
     "iopub.status.busy": "2024-11-11T17:15:58.423980Z",
     "iopub.status.idle": "2024-11-11T17:15:58.806641Z",
     "shell.execute_reply": "2024-11-11T17:15:58.805697Z",
     "shell.execute_reply.started": "2024-11-11T17:15:58.424290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:58.808270Z",
     "iopub.status.busy": "2024-11-11T17:15:58.807816Z",
     "iopub.status.idle": "2024-11-11T17:15:58.847858Z",
     "shell.execute_reply": "2024-11-11T17:15:58.846868Z",
     "shell.execute_reply.started": "2024-11-11T17:15:58.808232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-1/train.csv', encoding='ISO-8859-1')\n",
    "# Define path to video clips\n",
    "video_dir = '/kaggle/input/ml-hackathon-ec-campus-set-1/train_videos'\n",
    "\n",
    "\n",
    "# Function to get video file path from IDs\n",
    "def get_video_clip_path(row):\n",
    "    dialogue_id = row['Dialogue_ID']\n",
    "    utterance_id = row['Utterance_ID']\n",
    "    filename = f\"dia{dialogue_id}_utt{utterance_id}.mp4\"\n",
    "    return os.path.join(video_dir, filename)\n",
    "\n",
    "# Apply the function to get file paths for each sampled clip\n",
    "train_df['video_clip_path'] = train_df.apply(get_video_clip_path, axis=1)\n",
    "\n",
    "# Check sample paths\n",
    "print(train_df[['Dialogue_ID', 'Utterance_ID', 'video_clip_path']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:58.849645Z",
     "iopub.status.busy": "2024-11-11T17:15:58.849262Z",
     "iopub.status.idle": "2024-11-11T17:15:58.856583Z",
     "shell.execute_reply": "2024-11-11T17:15:58.855643Z",
     "shell.execute_reply.started": "2024-11-11T17:15:58.849599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:58.859005Z",
     "iopub.status.busy": "2024-11-11T17:15:58.857861Z",
     "iopub.status.idle": "2024-11-11T17:15:58.875275Z",
     "shell.execute_reply": "2024-11-11T17:15:58.874378Z",
     "shell.execute_reply.started": "2024-11-11T17:15:58.858937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define path to video clips\n",
    "df = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-1/test.csv', encoding='ISO-8859-1')\n",
    "video_dir = '/kaggle/input/ml-hackathon-ec-campus-set-1/test_videos'\n",
    "\n",
    "\n",
    "# Function to get video file path from IDs\n",
    "def get_video_clip_path(row):\n",
    "    dialogue_id = row['Dialogue_ID']\n",
    "    utterance_id = row['Utterance_ID']\n",
    "    filename = f\"dia{dialogue_id}_utt{utterance_id}.mp4\"\n",
    "    return os.path.join(video_dir, filename)\n",
    "\n",
    "# Apply the function to get file paths for each sampled clip\n",
    "df['video_clip_path'] = df.apply(get_video_clip_path, axis=1)\n",
    "\n",
    "# Check sample paths\n",
    "print(df[['Dialogue_ID', 'Utterance_ID', 'video_clip_path']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:58.879618Z",
     "iopub.status.busy": "2024-11-11T17:15:58.879146Z",
     "iopub.status.idle": "2024-11-11T17:15:59.871085Z",
     "shell.execute_reply": "2024-11-11T17:15:59.870121Z",
     "shell.execute_reply.started": "2024-11-11T17:15:58.879577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:59.872873Z",
     "iopub.status.busy": "2024-11-11T17:15:59.872312Z",
     "iopub.status.idle": "2024-11-11T17:15:59.887483Z",
     "shell.execute_reply": "2024-11-11T17:15:59.886323Z",
     "shell.execute_reply.started": "2024-11-11T17:15:59.872825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#print(train_df.head())\n",
    "sentences = train_df[[\"Utterance\",\"Sentiment\"]].values\n",
    "sentences = pd.DataFrame(sentences)\n",
    "\n",
    "sentences_test = df[\"Utterance\"].values\n",
    "sentences_test = pd.DataFrame(sentences_test)\n",
    "\n",
    "sentences.columns = ['Text', 'Sentiment']\n",
    "print(sentences)\n",
    "\n",
    "sentences_test.columns = ['Text']\n",
    "print(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:15:59.890249Z",
     "iopub.status.busy": "2024-11-11T17:15:59.889469Z",
     "iopub.status.idle": "2024-11-11T17:16:52.464471Z",
     "shell.execute_reply": "2024-11-11T17:16:52.463384Z",
     "shell.execute_reply.started": "2024-11-11T17:15:59.890200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Example DataFrame (replace with your actual sentences)\n",
    "# sentences = pd.DataFrame({'Text': [\"I love this!\", \"I hate that\", \"This is okay\"], 'Sentiment': ['positive', 'negative', 'neutral']})\n",
    "\n",
    "# Encode sentiments into numeric labels\n",
    "sentences['Sentiment'] = sentences['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(sentences, test_size=0.3, random_state=42)\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create custom Dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.texts = sentences['Text'].values\n",
    "        self.labels = sentences['Sentiment'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Encode text using BERT tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataset = SentimentDataset(train_data, tokenizer)\n",
    "test_dataset = SentimentDataset(test_data, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move batch to GPU if available\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} completed.\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print classification report for 3 sentiment classes\n",
    "print(classification_report(true_labels, predictions, target_names=['negative', 'positive', 'neutral']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:16:52.466389Z",
     "iopub.status.busy": "2024-11-11T17:16:52.465847Z",
     "iopub.status.idle": "2024-11-11T17:16:53.162654Z",
     "shell.execute_reply": "2024-11-11T17:16:53.161526Z",
     "shell.execute_reply.started": "2024-11-11T17:16:52.466351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming `test_data` contains only 'Text' column without the 'Sentiment' column\n",
    "# Replace the previous evaluation section with the following code\n",
    "\n",
    "test_sentences = sentences_test['Text'].values  # Only the text for prediction\n",
    "\n",
    "# Create a dataset for test data without labels\n",
    "class TestSentimentDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.texts = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        # Encode text using BERT tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "# Prepare DataLoader for test data\n",
    "test_dataset = TestSentimentDataset(test_sentences, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Map predictions back to sentiment labels\n",
    "sentiment_labels = ['negative', 'positive', 'neutral']\n",
    "predicted_sentiments = [sentiment_labels[pred] for pred in predictions]\n",
    "\n",
    "all_preds = predicted_sentiments\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "        'ID': range(1,len(test_sentences)+1),\n",
    "        'Emotion': all_preds\n",
    "    })\n",
    "    \n",
    "# Save the DataFrame to CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:16:53.164408Z",
     "iopub.status.busy": "2024-11-11T17:16:53.164015Z",
     "iopub.status.idle": "2024-11-11T17:17:04.935986Z",
     "shell.execute_reply": "2024-11-11T17:17:04.934738Z",
     "shell.execute_reply.started": "2024-11-11T17:16:53.164361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:17:04.938154Z",
     "iopub.status.busy": "2024-11-11T17:17:04.937757Z",
     "iopub.status.idle": "2024-11-11T17:20:10.464535Z",
     "shell.execute_reply": "2024-11-11T17:20:10.463700Z",
     "shell.execute_reply.started": "2024-11-11T17:17:04.938115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "# Path to the video directory\n",
    "video_dir = \"/kaggle/input/ml-hackathon-ec-campus-set-1/train\"  # Your video folder path\n",
    "\n",
    "# Create a directory to store audio files\n",
    "audio_dir = \"/kaggle/working/audio_files\"\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all video files in the directory\n",
    "for filename in os.listdir(video_dir):\n",
    "    if filename.endswith(('.mp4', '.avi', '.mov')):  # Adjust extensions as needed\n",
    "        video_path = os.path.join(video_dir, filename)\n",
    "        \n",
    "        # Load video file\n",
    "        video_clip = VideoFileClip(video_path)\n",
    "        \n",
    "        # Extract audio from the video\n",
    "        audio_clip = video_clip.audio\n",
    "        \n",
    "        # Save the audio file\n",
    "        audio_filename = os.path.splitext(filename)[0] + '.mp3'  # You can also use .wav\n",
    "        audio_path = os.path.join(audio_dir, audio_filename)\n",
    "        audio_clip.write_audiofile(audio_path)\n",
    "        \n",
    "        # Close clips after processing to free resources\n",
    "        video_clip.close()\n",
    "        audio_clip.close()\n",
    "\n",
    "print(\"Audio extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:20:10.468031Z",
     "iopub.status.busy": "2024-11-11T17:20:10.467089Z",
     "iopub.status.idle": "2024-11-11T17:20:55.549735Z",
     "shell.execute_reply": "2024-11-11T17:20:55.548300Z",
     "shell.execute_reply.started": "2024-11-11T17:20:10.467981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to your audio files directory\n",
    "audio_dir = \"/kaggle/working/audio_files\"  # Update with your path\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_audio_features(audio_file):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    # Mean of the MFCC features across time\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    \n",
    "    return mfcc_mean\n",
    "\n",
    "# Extract features for all audio files\n",
    "audio_features = []\n",
    "audio_filenames = []\n",
    "\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.mp3'):  # Adjust file extensions as needed\n",
    "        audio_file_path = os.path.join(audio_dir, filename)\n",
    "        features = extract_audio_features(audio_file_path)\n",
    "        audio_features.append(features)\n",
    "        audio_filenames.append(filename)\n",
    "\n",
    "# Convert to numpy array\n",
    "audio_features = np.array(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:20:55.552881Z",
     "iopub.status.busy": "2024-11-11T17:20:55.551880Z",
     "iopub.status.idle": "2024-11-11T17:20:55.590924Z",
     "shell.execute_reply": "2024-11-11T17:20:55.589851Z",
     "shell.execute_reply.started": "2024-11-11T17:20:55.552831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with ISO-8859-1 encoding\n",
    "file_path = \"/kaggle/input/ml-hackathon-ec-campus-set-1/train.csv\"  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Preview the data to check the columns\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Drop rows with missing 'Utterance' or 'Sentiment' columns\n",
    "df = df.dropna(subset=['Utterance', 'Sentiment'])\n",
    "\n",
    "# Preview cleaned data\n",
    "print(df[['Utterance', 'Sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:20:55.599812Z",
     "iopub.status.busy": "2024-11-11T17:20:55.596690Z",
     "iopub.status.idle": "2024-11-11T17:21:39.130531Z",
     "shell.execute_reply": "2024-11-11T17:21:39.129415Z",
     "shell.execute_reply.started": "2024-11-11T17:20:55.599747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline using BERT\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function to analyze sentiment of the utterance\n",
    "def analyze_text_sentiment(text):\n",
    "    result = sentiment_analyzer(text)\n",
    "    sentiment = result[0]['label']  # \"POSITIVE\" or \"NEGATIVE\"\n",
    "    return sentiment\n",
    "\n",
    "# Apply sentiment analysis to each utterance\n",
    "df['Predicted_Sentiment'] = df['Utterance'].apply(analyze_text_sentiment)\n",
    "\n",
    "# Map BERT sentiment output to numeric labels (positive: 1, negative: 0, neutral: 2)\n",
    "def sentiment_to_label(sentiment):\n",
    "    if sentiment == 'POSITIVE':\n",
    "        return 1\n",
    "    elif sentiment == 'NEGATIVE':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2  # Neutral\n",
    "\n",
    "df['Predicted_Sentiment_Label'] = df['Predicted_Sentiment'].apply(sentiment_to_label)\n",
    "\n",
    "# Preview the updated dataframe\n",
    "print(df[['Utterance', 'Sentiment', 'Predicted_Sentiment', 'Predicted_Sentiment_Label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:21:39.133313Z",
     "iopub.status.busy": "2024-11-11T17:21:39.132456Z",
     "iopub.status.idle": "2024-11-11T17:21:39.157114Z",
     "shell.execute_reply": "2024-11-11T17:21:39.156219Z",
     "shell.execute_reply.started": "2024-11-11T17:21:39.133261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Convert actual sentiment to numeric labels (positive: 1, negative: 0, neutral: 2)\n",
    "def actual_sentiment_to_label(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        return 1\n",
    "    elif sentiment == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2  # Neutral\n",
    "\n",
    "# Apply this function to the actual 'Sentiment' column\n",
    "df['Actual_Sentiment_Label'] = df['Sentiment'].apply(actual_sentiment_to_label)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(df['Actual_Sentiment_Label'], df['Predicted_Sentiment_Label'])\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\\n\", classification_report(df['Actual_Sentiment_Label'], df['Predicted_Sentiment_Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:21:39.158675Z",
     "iopub.status.busy": "2024-11-11T17:21:39.158372Z",
     "iopub.status.idle": "2024-11-11T17:58:43.002975Z",
     "shell.execute_reply": "2024-11-11T17:58:43.001833Z",
     "shell.execute_reply.started": "2024-11-11T17:21:39.158643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install moviepy\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "input_directory = '/kaggle/input/ml-hackathon-ec-campus-set-1/train/'  \n",
    "output_directory = '/kaggle/working/train_wav/'  \n",
    "\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.mp4'):\n",
    "        \n",
    "        mp4_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "      \n",
    "        wav_path = os.path.join(output_directory, filename.replace('.mp4', '.wav'))\n",
    "        \n",
    "        \n",
    "        video_clip = VideoFileClip(mp4_path)\n",
    "        audio_clip = video_clip.audio\n",
    "        \n",
    "       \n",
    "        audio_clip.write_audiofile(wav_path, codec='pcm_s16le')\n",
    "       \n",
    "        audio_clip.close()\n",
    "        video_clip.close()\n",
    "        \n",
    "        print(f'Converted {filename} to WAV format and saved as {wav_path}.')\n",
    "!pip install librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, csv_file, video_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with annotations\n",
    "            video_dir (string): Directory with all the videos\n",
    "            transform (callable, optional): Optional transform to be applied on frames\n",
    "        \"\"\"\n",
    "        # Try reading with utf-8 encoding and fall back to latin1 if needed\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"utf-8 encoding failed, trying 'latin1'\")\n",
    "            self.data = pd.read_csv(csv_file, encoding='latin1')\n",
    "        \n",
    "        self.video_dir = video_dir\n",
    "        self.transform = transform\n",
    "        self.sentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "\n",
    "    def extract_frames(self, video_path, max_frames=30):\n",
    "        \"\"\"Extract a fixed number of frames from the beginning of a video.\"\"\"\n",
    "        frames = []\n",
    "        \n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Warning: Video file not found: {video_path}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Warning: Could not open video: {video_path}\")\n",
    "                return None\n",
    "\n",
    "            frame_count = 0\n",
    "            while cap.isOpened() and frame_count < max_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                frames.append(frame)\n",
    "                frame_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing video {video_path}: {e}\")\n",
    "\n",
    "        finally:\n",
    "            if 'cap' in locals() and cap.isOpened():\n",
    "                cap.release()\n",
    "\n",
    "        return frames if frames else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "     if torch.is_tensor(idx):\n",
    "        idx = idx.tolist()\n",
    "\n",
    "    # Dynamically construct the filename\n",
    "     dialogue_id = str(int(self.data.iloc[idx]['Dialogue_ID']))\n",
    "     utt_id = str(int(self.data.iloc[idx]['Utterance_ID']))\n",
    "     video_name = f\"dia{dialogue_id}_utt{utt_id}.mp4\"\n",
    "     video_path = os.path.join(self.video_dir, video_name)\n",
    "\n",
    "    # Skip if the video file doesn't exist\n",
    "     if not os.path.exists(video_path):\n",
    "        print(f\"Skipping missing video: {video_name}\")\n",
    "        return torch.zeros((30, 3, 224, 224)), 1  # Default tensor and neutral label for missing videos\n",
    "    \n",
    "    # Process frames\n",
    "     frames = self.extract_frames(video_path)\n",
    "     if frames is None:\n",
    "        return torch.zeros((30, 3, 224, 224)), self.sentiment_map.get(\n",
    "            str(self.data.iloc[idx]['Sentiment']).lower().strip(), 1)\n",
    "    \n",
    "    # Pad or crop frames to ensure 30 frames\n",
    "     if len(frames) < 30:\n",
    "        frames += [torch.zeros((3, 224, 224))] * (30 - len(frames))\n",
    "     elif len(frames) > 30:\n",
    "        frames = frames[:30]\n",
    "    \n",
    "     frames = torch.stack(frames)\n",
    "     sentiment = str(self.data.iloc[idx]['Sentiment']).lower().strip()\n",
    "     label = self.sentiment_map.get(sentiment, 1)  # Default to neutral if unknown\n",
    "    \n",
    "     return frames, label\n",
    "class SentimentResNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(SentimentResNet, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames = x.size(0), x.size(1)\n",
    "        x = x.view(-1, x.size(2), x.size(3), x.size(4))\n",
    "        x = self.resnet(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(batch_size, num_frames, -1)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "                \n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    model.train()\n",
    "    scaler = GradScaler()  # Initialize scaler for mixed precision\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (frames, labels) in enumerate(train_loader):\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():  # Enable mixed precision\n",
    "                outputs = model(frames)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                      f'Step [{i + 1}/{len(train_loader)}], '\n",
    "                      f'Loss: {running_loss / 100:.4f}, '\n",
    "                      f'Accuracy: {100 * correct / total:.2f}%')\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "try:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = VideoFrameDataset(\n",
    "        csv_file='/kaggle/input/ml-hackathon-ec-campus-set-1/train.csv',\n",
    "        video_dir='/kaggle/input/ml-hackathon-ec-campus-set-1/train',\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=4, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    model = SentimentResNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=10, device=device)\n",
    "    \n",
    "    torch.save(model.state_dict(), 'sentiment_resnet.pth')\n",
    "    print(\"Training completed successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in main execution: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10116655,
     "sourceId": 88319,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
